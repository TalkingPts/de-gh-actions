name: Moving collections manually
on:
  workflow_dispatch:
    inputs:
      collection:
        type: choice
        description: "Collection name"
        required: true
        options:
          - translationorders
          - translationengineorders
          - textmessages
          - messages
          - students
          - contacts
          - users
          - institutions
      operation:
        type: choice
        description: "Operation type"
        required: true
        options:
          - insert
          - update
          - delete
          - replace
      year:
        type: string
        description: "Year (YYYY format)"
        required: true
      month:
        type: string
        description: "Month (MM format)"
        required: true 
      day:
        type: string
        description: "Day (DD format)"
        required: true

jobs:
  deploy:
    name: Move to tobeprocessed
    strategy:
      matrix:
        collection: ["${{ inputs.collection }}"]
        operation: ["${{ inputs.operation }}"]
        hour:
          [
            "00",
            "01",
            "02",
            "03",
            "04",
            "05",
            "06",
            "07",
            "08",
            "09",
            "10",
            "11",
            "12",
            "13",
            "14",
            "15",
            "16",
            "17",
            "18",
            "19",
            "20",
            "21",
            "22",
            "23",
          ]

    runs-on: ubuntu-latest
    # These permissions are needed to interact with GitHub's OIDC Token endpoint.
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-west-1

      - name: Copy files to the tobeprocessed prefix
        env:
          S3_SRC_BUCKET: ${{ secrets.S3_SRC_BUCKET }}
          S3_DST_BUCKET: ${{ secrets.S3_DST_BUCKET }}
        run: |
          log_filename=${{ matrix.collection }}_${{ inputs.year }}${{ inputs.month }}${{ inputs.day }}_${{ matrix.operation }}-$(date +"%Y%m%d").log

          aws s3 mv \
          $S3_SRC_BUCKET/${{ matrix.collection }}/${{ matrix.operation }}/year=${{ inputs.year }}/month=${{ inputs.month }}/day=${{ inputs.day }}/hour=${{ matrix.hour }}/ \
          $S3_DST_BUCKET/${{ matrix.collection }}/${{ matrix.operation }}/year=${{ inputs.year }}/month=${{ inputs.month }}/day=${{ inputs.day }}/hour=${{ matrix.hour }}/ \
          --recursive \
          --no-progress \
          > $log_filename

          if [ -s ${log_filename} ]
          then
              aws s3 mv ./$log_filename $S3_DST_BUCKET/aws-mv-logs/$log_filename --no-progress
          else
              echo "Skipping $log_filename upload."
          fi